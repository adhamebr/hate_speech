{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('./nlp_assignment-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the annotations metadata\n",
    "annotations_path = './data/hate-speech-dataset/annotations_metadata.csv'\n",
    "annotations_df = pd.read_csv(annotations_path)\n",
    "\n",
    "# Base paths for train and test files\n",
    "train_base_path = './data/hate-speech-dataset/sampled_train'\n",
    "test_base_path = './data/hate-speech-dataset/sampled_test'\n",
    "\n",
    "# Function to load text files and merge with metadata\n",
    "def load_and_merge_texts(file_base_path, annotations_df):\n",
    "    merged_data = []\n",
    "    for file_id in os.listdir(file_base_path):\n",
    "        file_path = os.path.join(file_base_path, file_id)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            metadata = annotations_df[annotations_df['file_id'] == file_id.split('.')[0]].iloc[0]\n",
    "            merged_data.append({\n",
    "                'file_id': metadata['file_id'],\n",
    "                'user_id': metadata['user_id'],\n",
    "                'subforum_id': metadata['subforum_id'],\n",
    "                'num_contexts': metadata['num_contexts'],\n",
    "                'label': metadata['label'],\n",
    "                'text': text\n",
    "            })\n",
    "    return pd.DataFrame(merged_data)\n",
    "\n",
    "# Load and merge train and test data\n",
    "train_data = load_and_merge_texts(train_base_path, annotations_df)\n",
    "test_data = load_and_merge_texts(test_base_path, annotations_df)\n",
    "\n",
    "# # Save to CSV\n",
    "# train_data.to_csv('./data/train_data.csv', index=False)\n",
    "# test_data.to_csv('./data/test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming filtered_data is your DataFrame and it includes the 'label' column\n",
    "\n",
    "# Convert the 'label' column to a categorical type if it isn't already\n",
    "test_data['label'] = test_data['label'].astype('category')\n",
    "\n",
    "# Use the category codes as numerical labels\n",
    "test_data['label_id'] = test_data['label'].cat.codes\n",
    "test_data.to_csv('./data/hate-speech-dataset/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum text length: 3\n",
      "Maximum text length: 1582\n",
      "Average text length: 104.37\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Calculate lengths of each text entry\n",
    "text_lengths = train_data['text'].apply(len)\n",
    "\n",
    "# Calculate minimum, maximum, and average length\n",
    "min_length = text_lengths.min()\n",
    "max_length = text_lengths.max()\n",
    "average_length = text_lengths.mean()\n",
    "\n",
    "print(f'Minimum text length: {min_length}')\n",
    "print(f'Maximum text length: {max_length}')\n",
    "print(f'Average text length: {average_length:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/adham.ibrahim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "train_data['text'] = train_data['text'].str.lower()\n",
    "\n",
    "# Define a function to remove stop words from a single string\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the 'remove_stopwords' function to the 'Text' column\n",
    "train_data['text'] = train_data['text'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "# Define a function to perform stemming on a single string\n",
    "def perform_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_words = []\n",
    "    for token in tokens:\n",
    "        stemmed_words.append(stemmer.stem(token))\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Apply the 'perform_stemming' function to the 'Text' column\n",
    "train_data['text'] = train_data['text'].apply(perform_stemming)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "#print(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Define a function to remove non-alphabetic characters from a single string\n",
    "def remove_non_alphabetic(text):\n",
    "    pattern = r'[^a-zA-Z\\s]'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "# Apply the 'remove_non_alphabetic' function to the 'Text' column\n",
    "train_data['text'] = train_data['text'].apply(remove_non_alphabetic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           br  tapio \n",
       "1                                         thank  c  r \n",
       "2    would like see white peopl get togeth get us w...\n",
       "3    sad happen want take think want date one negro...\n",
       "4                        http  rnebarkashovrufotoffjpg\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http  rnebarkashovrufotoffjpg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming combined_data is your DataFrame\n",
    "\n",
    "# Keep rows where the 'text' column does NOT start with 'http'\n",
    "filtered_data = train_data[~train_data['text'].str.startswith('http')]\n",
    "\n",
    "# Now, filtered_data contains only the rows where the 'text' column doesn't start with \"http\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14096493_3</td>\n",
       "      <td>589735</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>br  tapio</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14097600_1</td>\n",
       "      <td>598929</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>thank  c  r</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13946095_2</td>\n",
       "      <td>594398</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>would like see white peopl get togeth get us w...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13483062_1</td>\n",
       "      <td>575681</td>\n",
       "      <td>1346</td>\n",
       "      <td>1</td>\n",
       "      <td>hate</td>\n",
       "      <td>sad happen want take think want date one negro...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31706302_10</td>\n",
       "      <td>586694</td>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>appli techniqu one mani occas seen consider su...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_id  user_id  subforum_id  num_contexts   label  \\\n",
       "0   14096493_3   589735         1381             0  noHate   \n",
       "1   14097600_1   598929         1381             0  noHate   \n",
       "2   13946095_2   594398         1388             0  noHate   \n",
       "3   13483062_1   575681         1346             1    hate   \n",
       "5  31706302_10   586694         1363             0  noHate   \n",
       "\n",
       "                                                text   type  \n",
       "0                                         br  tapio   train  \n",
       "1                                       thank  c  r   train  \n",
       "2  would like see white peopl get togeth get us w...  train  \n",
       "3  sad happen want take think want date one negro...  train  \n",
       "5  appli techniqu one mani occas seen consider su...  train  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3800815/969888658.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['label'] = filtered_data['label'].astype('category')\n",
      "/tmp/ipykernel_3800815/969888658.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['label_id'] = filtered_data['label'].cat.codes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming filtered_data is your DataFrame and it includes the 'label' column\n",
    "\n",
    "# Convert the 'label' column to a categorical type if it isn't already\n",
    "filtered_data['label'] = filtered_data['label'].astype('category')\n",
    "\n",
    "# Use the category codes as numerical labels\n",
    "filtered_data['label_id'] = filtered_data['label'].cat.codes\n",
    "\n",
    "# Now, filtered_data has a new column 'label_id' with numeric encoding of the 'label' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14096493_3</td>\n",
       "      <td>589735</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>br  tapio</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14097600_1</td>\n",
       "      <td>598929</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>thank  c  r</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13946095_2</td>\n",
       "      <td>594398</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>would like see white peopl get togeth get us w...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13483062_1</td>\n",
       "      <td>575681</td>\n",
       "      <td>1346</td>\n",
       "      <td>1</td>\n",
       "      <td>hate</td>\n",
       "      <td>sad happen want take think want date one negro...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31706302_10</td>\n",
       "      <td>586694</td>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>appli techniqu one mani occas seen consider su...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>30586792_1</td>\n",
       "      <td>739402</td>\n",
       "      <td>1348</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>next time see someon pant fall  help</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>14100101_1</td>\n",
       "      <td>599177</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>get ride see time summer cool need get someon ...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>14672042_2</td>\n",
       "      <td>575713</td>\n",
       "      <td>1371</td>\n",
       "      <td>6</td>\n",
       "      <td>hate</td>\n",
       "      <td>likelyhood  s jew paint road skank follow</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>13494648_1</td>\n",
       "      <td>575123</td>\n",
       "      <td>1395</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>compar pictur pictur serb nt see much differ a...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>14101084_1</td>\n",
       "      <td>574315</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "      <td>use enter hors competit thrown one broke leg</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2367 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_id  user_id  subforum_id  num_contexts   label  \\\n",
       "0      14096493_3   589735         1381             0  noHate   \n",
       "1      14097600_1   598929         1381             0  noHate   \n",
       "2      13946095_2   594398         1388             0  noHate   \n",
       "3      13483062_1   575681         1346             1    hate   \n",
       "5     31706302_10   586694         1363             0  noHate   \n",
       "...           ...      ...          ...           ...     ...   \n",
       "2387   30586792_1   739402         1348             0  noHate   \n",
       "2388   14100101_1   599177         1381             0  noHate   \n",
       "2389   14672042_2   575713         1371             6    hate   \n",
       "2390   13494648_1   575123         1395             0  noHate   \n",
       "2391   14101084_1   574315         1381             0  noHate   \n",
       "\n",
       "                                                   text   type  label_id  \n",
       "0                                            br  tapio   train         1  \n",
       "1                                          thank  c  r   train         1  \n",
       "2     would like see white peopl get togeth get us w...  train         1  \n",
       "3     sad happen want take think want date one negro...  train         0  \n",
       "5     appli techniqu one mani occas seen consider su...  train         1  \n",
       "...                                                 ...    ...       ...  \n",
       "2387              next time see someon pant fall  help    test         1  \n",
       "2388  get ride see time summer cool need get someon ...   test         1  \n",
       "2389         likelyhood  s jew paint road skank follow    test         0  \n",
       "2390  compar pictur pictur serb nt see much differ a...   test         1  \n",
       "2391      use enter hors competit thrown one broke leg    test         1  \n",
       "\n",
       "[2367 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('./data/hate-speech-dataset/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "hate      953\n",
       "noHate    938\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
